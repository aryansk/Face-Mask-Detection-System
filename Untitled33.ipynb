{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the uploaded ZIP file (replace 'your_file.zip' with the actual file name)\n",
        "zip_path = \"/content/test.zip\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/test\")  # Extract to the 'dataset' directory\n",
        "\n",
        "# Optionally, check extracted files\n",
        "print(os.listdir(\"/content/test\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkbJ07Hfkrij",
        "outputId": "43f06db3-b7e7-4dc4-c565-6c7067379e34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the uploaded ZIP file (replace 'your_file.zip' with the actual file name)\n",
        "zip_path = \"/content/train.zip\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/train\")  # Extract to the 'dataset' directory\n",
        "\n",
        "# Optionally, check extracted files\n",
        "print(os.listdir(\"/content/train\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdzu5inJk1yC",
        "outputId": "0eca18b8-c60f-4a34-ce8a-3a8e4bebb1be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "#import keras # Remove this line as we are using tf.keras\n",
        "#import keras.backend as k # Remove as we are using tf.keras.backend\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,SpatialDropout2D,Flatten,Dropout,Dense # Update import path\n",
        "from tensorflow.keras.models import Sequential,load_model # Update import path\n",
        "from tensorflow.keras.optimizers import Adam # Update import path\n",
        "from tensorflow.keras.preprocessing import image # Update import path\n",
        "import cv2\n",
        "import datetime\n",
        "\n",
        "\n",
        "# UNCOMMENT THE FOLLOWING CODE TO TRAIN THE CNN FROM SCRATCH\n",
        "\n",
        "# BUILDING MODEL TO CLASSIFY BETWEEN MASK AND NO MASK\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(MaxPooling2D() )\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D() )\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D() )\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Update import path\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(150,150),\n",
        "        batch_size=16 ,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(150,150),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Replace fit_generator with fit\n",
        "model_saved=model.fit(\n",
        "        training_set,\n",
        "        epochs=10,\n",
        "        validation_data=test_set,\n",
        "\n",
        "        )\n",
        "\n",
        "model.save('my_model.keras',model_saved)\n",
        "\n",
        "#To test for individual images\n",
        "\n",
        "mymodel=load_model('my_model.keras')\n",
        "#test_image=image.load_img('C:/Users/Karan/Desktop/ML Datasets/Face Mask Detection/Dataset/test/without_mask/30.jpg',target_size=(150,150,3))\n",
        "test_image=image.load_img(r'/content/mask.png',\n",
        "                          target_size=(150,150,3))\n",
        "test_image\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "mymodel.predict(test_image)[0][0]\n",
        "\n",
        "\n",
        "# IMPLEMENTING LIVE DETECTION OF FACE MASK\n",
        "\n",
        "mymodel=load_model('my_model.keras')\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "while cap.isOpened():\n",
        "    _,img=cap.read()\n",
        "    face=face_cascade.detectMultiScale(img,scaleFactor=1.1,minNeighbors=4)\n",
        "    for(x,y,w,h) in face:\n",
        "        face_img = img[y:y+h, x:x+w]\n",
        "        cv2.imwrite('temp.jpg',face_img)\n",
        "        test_image=image.load_img('temp.jpg',target_size=(150,150,3))\n",
        "        test_image=image.img_to_array(test_image)\n",
        "        test_image=np.expand_dims(test_image,axis=0)\n",
        "        pred=mymodel.predict(test_image)[0][0]\n",
        "        if pred==1:\n",
        "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
        "            cv2.putText(img,'NO MASK',((x+w)//2,y+h+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
        "        else:\n",
        "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
        "            cv2.putText(img,'MASK',((x+w)//2,y+h+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3)\n",
        "        datet=str(datetime.datetime.now())\n",
        "        cv2.putText(img,datet,(400,450),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)\n",
        "\n",
        "    cv2.imshow('img',img)\n",
        "\n",
        "    if cv2.waitKey(1)==ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjEt_9f_lPGB",
        "outputId": "9a1b8e09-cad8-467c-9f0d-9c918bfce54f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1315 images belonging to 1 classes.\n",
            "Found 194 images belonging to 1 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.9702 - loss: 0.0434 - val_accuracy: 1.0000 - val_loss: 2.2921e-26\n",
            "Epoch 2/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.3247e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 3/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.5452e-19 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 4/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.2323e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 5/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 6.8794e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 6/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 5.9067e-21 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 7/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 2.5147e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 8/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.5948e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 9/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 1.0818e-19 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "Epoch 10/10\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.9513e-20 - val_accuracy: 1.0000 - val_loss: 2.2107e-26\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n"
          ]
        }
      ]
    }
  ]
}